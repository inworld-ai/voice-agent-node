# DO NOT EDIT THIS FILE DIRECTLY
# Copy this file to .env.local and enter your own values
#

# =============================================================================
# REALTIME API SERVER CONFIGURATION
# =============================================================================

# Realtime API Server URL (WebSocket)
# Default: ws://localhost:4000
NEXT_PUBLIC_REALTIME_API_URL=ws://localhost:4000

# Realtime Server Host (for HTTP endpoints if needed)
# Default: localhost
NEXT_PUBLIC_REALTIME_SERVER_HOST=localhost

# Realtime Server Port (for HTTP endpoints if needed)
# Default: 4000
NEXT_PUBLIC_REALTIME_SERVER_PORT=4000

# =============================================================================
# INWORLD API CONFIGURATION
# =============================================================================

# Inworld API Key (single key for both client and server)
# Get your API key from https://platform.inworld.ai/
# Required: Used for WebSocket authentication, character generation, and voice cloning
# Note: For voice cloning functionality, this key must have write permissions in Inworld Studio
# 
# DEV ONLY: This key is automatically exposed to the client via next.config.mjs
# For production, API keys should be kept server-side only
INWORLD_API_KEY="aTh6SjdwT2FKOEFORUV2WXJ6VmVnRmFEQVdjMlNyNEc6bkR0NVNFUU9zRENWdVk1M3pTYjRPT0lJYURwUzF6Z0dsWFZYN2k3UGtxNnJvWG1BU2pPc05ydkQyRVBESzNLMA=="

# Inworld Workspace
# Required for voice cloning functionality
# Set to your Inworld workspace name
# Voice cloning will fail with an error if this is not set
# This is automatically exposed to the client via next.config.mjs
INWORLD_WORKSPACE=voiceagent

# LLM Provider for Character Generation
# Options: 'groq', 'openai', 'anthropic'
# Default: 'groq'
CHARACTER_GENERATION_LLM_PROVIDER=groq

# LLM Model Name for Character Generation
# Default: 'llama-3.3-70b-versatile' (for Groq)
# Examples:
#   - Groq: 'llama-3.3-70b-versatile'
#   - OpenAI: 'gpt-4o-mini'
#   - Anthropic: 'claude-3-5-sonnet-20241022'
CHARACTER_GENERATION_LLM_MODEL_NAME=llama-3.3-70b-versatile

# =============================================================================
# FEATURE FLAGS
# =============================================================================

# Enable latency reporting
# Default: false
NEXT_PUBLIC_ENABLE_LATENCY_REPORTING=false
